{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries & The Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "### Train and Test Data Exploration\n",
    "Display the ```head()``` to familiarize ourself with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined dataset description of train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine train and test dataset\n",
    "combined_data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for percentage of missing values in each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of missing values:')\n",
    "print('-----------------------------')\n",
    "print(combined_data.isnull().sum().sort_values(ascending=False)[1:] / 10695 * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution of Target Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for imbalance\n",
    "sns.countplot(train['Segmentation'], order=['A','B','C','D']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target array is balance, so it is a balance classifiction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot The Distribution of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the distribution of numerical features\n",
    "train.hist(bins=50,figsize=(10,10),grid=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of numerical features are right skewed. So, we need to transform it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicate\n",
    "print('Duplicated value(s) on the train dataset : ', train.duplicated().sum())\n",
    "print('Duplicated value(s) on the test dataset  : ', test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing Data\n",
    "We will start with the most missing values, and then continuing our way to the least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Work_Experience\n",
    "\n",
    "The missing values will be filled in the Feature Engineering Section, because we will need the missing values there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Family_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('Family_Size', hue='Segmentation', data=train, hue_order=['A','B','C','D']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with mode\n",
    "train['Family_Size'].fillna(train['Family_Size'].mode()[0], inplace=True)\n",
    "test['Family_Size'].fillna(test['Family_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ever_Married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('Ever_Married', hue='Segmentation', data=train, hue_order=['A','B','C','D']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with mode\n",
    "train['Ever_Married'].fillna(train['Ever_Married'].mode()[0], inplace=True)\n",
    "test['Ever_Married'].fillna(test['Ever_Married'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y='Profession', hue='Segmentation', data=train, hue_order=['A','B','C','D']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the artists are in segment C and most of the Healthcare are in segment D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train['Profession'].isnull() & (train['Segmentation']=='C')),['Profession']] = 'Artist'\n",
    "train.loc[(train['Profession'].isnull() & (train['Segmentation']=='D')),['Profession']] = 'Healthcare'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the rest with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with mode\n",
    "train['Profession'].fillna(train['Profession'].mode()[0], inplace=True)\n",
    "test['Profession'].fillna(test['Profession'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('Var_1', hue='Segmentation', data=train, hue_order=['A','B','C','D']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with mode\n",
    "train['Var_1'].fillna(train['Var_1'].mode()[0], inplace=True)\n",
    "test['Var_1'].fillna(test['Var_1'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Graduated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('Graduated', hue='Segmentation', data=train, hue_order=['A','B','C','D']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train['Graduated'].isnull() & (train['Segmentation']=='D')), ['Graduated']] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Graduated'].fillna(train['Graduated'].mode()[0], inplace=True)\n",
    "test['Graduated'].fillna(test['Graduated'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Any Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fill missing data in Work_Experience later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "### Copy and Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy features that are needed later\n",
    "target_array = train['Segmentation'].copy()\n",
    "test_id = test['ID'].copy()\n",
    "\n",
    "#drop features\n",
    "train.drop(['Segmentation'], axis=1, inplace=True)\n",
    "\n",
    "print('train shape: ', train.shape)\n",
    "print('test shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Work_Experience_given feature\n",
    "train['Work_Experience_is_given']=train['Work_Experience'].notnull()*1\n",
    "test['Work_Experience_is_given']=train['Work_Experience'].notnull()*1\n",
    "\n",
    "#fill missing values\n",
    "train['Work_Experience'].fillna(train['Work_Experience'].mode()[0], inplace=True)\n",
    "test['Work_Experience'].fillna(test['Work_Experience'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for feature in ['Gender','Ever_Married','Graduated','Profession','Spending_Score','Var_1']:\n",
    "    train[feature]=le.fit_transform(train[feature])\n",
    "    test[feature]=le.transform(test[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)\n",
    "test = pd.DataFrame(scaler.transform(test), columns=test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a normality test function\n",
    "def normalityTest(data, alpha=0.05):\n",
    "    \"\"\"data (array)   : The array containing the sample to be tested.\n",
    "\t   alpha (float)  : Significance level.\n",
    "\t   return True if data is normal distributed\"\"\"\n",
    "    \n",
    "    from scipy import stats\n",
    "    \n",
    "    statistic, p_value = stats.normaltest(data)\n",
    "    \n",
    "    #null hypothesis: array comes from a normal distribution\n",
    "    if p_value < alpha:  \n",
    "        #The null hypothesis can be rejected\n",
    "        is_normal_dist = False\n",
    "    else:\n",
    "        #The null hypothesis cannot be rejected\n",
    "        is_normal_dist = True\n",
    "    \n",
    "    return is_normal_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "#check normality of all numericaal features and transform it if not normal distributed\n",
    "for feature in train.columns:\n",
    "    if (train[feature].dtype != 'object'):\n",
    "        if normalityTest(train[feature]) == False:\n",
    "            train[feature] = np.log1p(train[feature])\n",
    "            test[feature] = np.log1p(test[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features matrix (X) and target array (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "y = target_array\n",
    "\n",
    "X_to_be_predicted = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Model\n",
    "We begin by splitting data into two subsets: for training data and for testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training : LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#tuning the model\n",
    "model = LGBMClassifier(learning_rate=0.1,\n",
    "                       n_estimators=1200,\n",
    "                       max_depth=5,\n",
    "                       min_child_weight=1,\n",
    "                       gamma=0,\n",
    "                       subsample=0.8,\n",
    "                       colsample_bytree=0.8,\n",
    "                       nthread=4,\n",
    "                       scale_pos_weight=3,\n",
    "                       seed=27)\n",
    "\n",
    "#fitting\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a prediction\n",
    "\n",
    "y_predict = model.predict(X_to_be_predicted)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results to a file\n",
    "\n",
    "results = pd.DataFrame({'ID': test_id, 'Segmentation': y_predict})\n",
    "results.to_csv('my_submission.csv', index=False)\n",
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
